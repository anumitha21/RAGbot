# ğŸ§  RAG Chatbot

**RAG Chatbot** is a minimal, plug-and-play Retrieval-Augmented Generation (RAG) framework that lets you chat with content scraped from websites or loaded from PDFs. Powered by LLMs like **Groq** and **Gemini**.

---

## âœ¨ Features

- ğŸŒ Web scraping with LangChain's `WebBaseLoader`
- ğŸ“„ PDF ingestion using `PyPDF`
- ğŸ§  Smart context retrieval via ChromaDB
- ğŸ¤– Answers powered by Groq or Gemini LLMs
- ğŸ’» Notebook-ready pipeline

---

## ğŸ› ï¸ Requirements

- ğŸ Python 3.8+
- ğŸ“¦ pip
- ğŸ““ Jupyter Notebook 
- ğŸ” API keys for:
  - Groq
  - Google Gemini

---

## ğŸ“¦ Installation

1. ğŸš€ **Clone the repo**
   ```bash
   git clone https://github.com/yourusername/rag-chatbot.git
   cd rag-chatbot
   ```

2. ğŸ§ª **Create & activate virtual environment**
   ```bash
   python -m venv rag
   # On Windows:
   rag\Scripts\activate
   # On Unix or MacOS:
   source rag/bin/activate
   ```

3. ğŸ“¥ **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸ” Environment Variables

Create a `.env` file in the project root:

```env
GROQ_API_KEY=your-groq-api-key
GOOGLE_API_KEY=your-gemini-api-key
```

> ğŸ’¡ Use `.env` for safe and flexible key management.

---

## ğŸš€ Running the Project

### ğŸ““ Run via Jupyter Notebook
```bash
jupyter notebook RAG_CHATBOT.ipynb
```


## ğŸ’¡ Usage

- ğŸ§¾ Load data from a **URL** or **PDF**
- â“ Ask natural language questions
- ğŸ“š RAG retrieves relevant context
- ğŸ¤– LLM generates intelligent, context-aware answers

---

